{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repaso de teoría de probabilidad\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://storage.needpix.com/rsynced_images/bayesian-2889576_1280.png\" width=\"200px\" height=\"180px\" />\n",
    "\n",
    "> Como vimos en el ejemplo introductorio, este curso se enfoca en distribuciones de probabilidad complejas, que involucran una gran cantidad de variables y sus interacciones.\n",
    "\n",
    "> Por esa razón haremos un breve repaso de los conceptos que necesitaremos de teoría de probabilidad.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Repasar definiciones y resultados básicos de teoría de probabilidad.\n",
    "> - Entender el concepto de independencia.\n",
    "\n",
    "> **Referencias:**\n",
    "> \n",
    "> - Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Cap. 2.\n",
    "\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://storage.needpix.com/rsynced_images/bayesian-2889576_1280.png.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Distribuciones de probabilidad.\n",
    "\n",
    "Normalmente cuando usamos la palabra \"probabilidad\" o vocablos relacionados en la vida cotidiana, nos referimos al grado de confianza que tenemos de que un evento con incertidumbre ocurra.\n",
    "\n",
    "- Por ejemplo: \"es probable que hoy llueva\"; \"probablemente el Bayern Münich gane la champions\".\n",
    "\n",
    "La **teoría de probabilidad** formaliza las bases para discutir este tipo de afirmaciones, y nos da las reglas que deben cumplir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir las *distribuciones de probabilidad*, son necesarios dos ingredientes:\n",
    "\n",
    "1. **Espacio de resultados**: conjunto de posibles resultados, el cual denotamos por $\\Omega$.\n",
    "\n",
    "   - Ejemplo: en la tirada de un dado podríamos considerar $\\Omega=\\{1, 2, 3, 4, 5, 6\\}$.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Eventos**: los eventos son **subconjuntos** del espacio de resultados a los que queremos asignar una probabilidad. El conjunto de todos los eventos lo denotamos por $\\mathcal{S}$.\n",
    "\n",
    "   - Ejemplo: en el ejemplo de los dados, el *evento* $\\{6\\}$ representa el caso donde el dado cae en seis. El *evento* $\\{1, 3, 5\\}$ representa el caso de que caiga impar.\n",
    "   \n",
    "   Es importante recalcar de que los eventos son subconjuntos más no elementos del espacio de resultados. Formalmente,\n",
    "   \n",
    "   $$\\forall \\alpha \\in \\mathcal{S}, \\alpha \\subseteq \\Omega.$$\n",
    "   \n",
    "   La teoría de probabilidad, requiere que el espacio de todos los eventos, $\\mathcal{S}$, satisfaca tres propiedades básicas:\n",
    "   \n",
    "   - $\\emptyset, \\Omega \\in \\mathcal{S}$: contiene al evento vacío y al evento trivial.\n",
    "   - $\\alpha,\\beta \\in \\mathcal{S} \\Rightarrow \\alpha \\cup \\beta \\in \\mathcal{S}$: cerrado bajo la unión.\n",
    "   - $\\alpha \\in \\mathcal{S} \\Rightarrow (\\Omega - \\alpha) \\in \\mathcal{S}$: cerrado bajo complemento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Definición.* Una **distribución de probabilidad** $P$ sobre $(\\Omega, \\mathcal{S})$ es una función del espacio de eventos en los números reales $P:\\mathcal{S} \\to \\mathbb{R}$ tal que:\n",
    "> - $P(\\alpha) \\geq 0$, para todo $\\alpha \\in \\mathcal{S}$;\n",
    "> - $P(\\Omega) = 1$; y\n",
    "> - Si $\\alpha, \\beta \\in \\mathcal{S}$ y $\\alpha \\cap \\beta = \\emptyset$, entonces $P(\\alpha \\cup \\beta) = P(\\alpha) + P(\\beta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que la anterior definición nos dice que:\n",
    "1. Todas las probabilidades son positivas,\n",
    "2. la probabilidad del evento trivial (todos los posibles resultados) tiene la máxima probabilidad que es de 1,\n",
    "3. la probabilidad de la unión de eventos mutuamente exclusivos es la suma de las probabilidades de los eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propiedad 3 en la anterior definición se puede extender para cantidades arbitrarias de eventos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Proposición.* Si $P$ es una distribución de probabilidad sobre $(\\Omega, \\mathcal{S})$ y $\\alpha_1,\\dots\\alpha_k\\in\\mathcal{S}$, con $k\\in\\mathbb{N}$, son tales que $\\alpha_i \\cap \\alpha_j = \\emptyset$ para todo $i,j \\leq k$, entonces:\n",
    ">\n",
    "> $$P(\\alpha_1 \\cup \\dots \\cup \\alpha_k) = P(\\alpha_1) + \\dots + P(\\alpha_k).$$\n",
    "\n",
    "> *Prueba.* En clase ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, la definición implica lo siguiente:\n",
    "\n",
    "> *Proposición.* Si $P$ es una distribución de probabilidad sobre $(\\Omega, \\mathcal{S})$, entonces:\n",
    ">\n",
    "> (i) $P(\\emptyset)=0$; y\n",
    ">\n",
    "> (ii) $P(\\alpha \\cup \\beta) = P(\\alpha) + P(\\beta) - P(\\alpha \\cap \\beta)$, para todo $\\alpha, \\beta \\in \\mathcal{S}$.\n",
    "\n",
    "> *Prueba.* En clase ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Interpretación de la probabilidad\n",
    "\n",
    "Antes de proseguir, discutamos la interpretación que podemos asignar a las distribuciones de probabilidad.\n",
    "\n",
    "Intuitivamente, la probabilidad $P(\\alpha)$ de un evento $\\alpha$ cuantifica el grado de confianza que tenemos en que $\\alpha$ va a ocurrir. En los casos extremos:\n",
    " - Si $P(\\alpha)=1$, estamos seguros de que alguno de los resultados en $\\alpha$ ocurrirá;\n",
    " - si por el contrario $P(\\alpha)=0$, consideramos que todos los resultados en $\\alpha$ son imposibles.\n",
    "\n",
    "Otros valores representan grados de confianza que yacen entre estos extremos.\n",
    "\n",
    "Sin embargo, esto no nos dice nada acerca de lo que significan los números como tal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretacion frecuentista:**\n",
    "\n",
    "Bajo esta interpretación, vemos las probabilidades como frecuencias de eventos. Esto es, la probabilidad de un evento corresponde con la fracción de veces que ese evento ocurre si el experimento se repitiera de manera *indefinida*.\n",
    "\n",
    "Esta interpretación resulta muy intuitiva cuando hablamos acerca de fenómenos físicos concretos: tirar una moneda, tirar un dado, juegos de cartas, entre otros. Por otra parte, es fácil verificar que las frecuencias satisfacen todos los requerimientos de las distribuciones de probabilidad.\n",
    "\n",
    "Sin embargo, esta interpretación no es para nada intuitiva cuando consideramos un evento como \"lloverá mañana\". En este caso resulta poco claro como definir la frecuencia de un evento como este."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación subjetiva:**\n",
    "\n",
    "Esta interpretación representa una afirmación subjetiva del grado de confianza de que el evento ocurrirá.\n",
    "\n",
    "Es decir, si yo digo \"Lloverá mañana con una probabilidad de $30$%\", estoy expresando mi grado de confianza en cuanto a la ocurrencia de ese evento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Conceptos básicos en teoría de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Probabilidad condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el concepto base para **incorporar evidencia (información)** a nuestros análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que estamos observando cierto conjunto de estudiantes en el curso de modelos gráficos probabilísticos. El espacio de resultados es simplemente todos los estudiantes en la población.\n",
    "\n",
    "Supongamos que queremos razonar acerca de las variables de inteligencia y nota final de los estudiantes.\n",
    "\n",
    "Definamos los siguiente eventos:\n",
    " - $\\alpha$: todos los estudiantes con notas iguales o superiores a 9.\n",
    " - $\\beta$: todos los estudiantes que son muy inteligentes.\n",
    " \n",
    "De forma que, usando la distribución de probabilidad sobre esta situación podemos averiguar la probabilidad de cada uno de estos eventos, así como la probabilidad de $\\alpha \\cap \\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo esto en mente, supongamos que sabemos que cierto estudiante obtuvo una nota superior a 9. ¿Qué nos dice esto acerca de us inteligencia?\n",
    "\n",
    "Este tipo de preguntas surgen a cada momento en problemas reales, como ya lo vimos en la motivación.\n",
    "\n",
    "La respuesta a esta pregunta viene dada por la noción de **probabilidad condicional**. Formalmente, \n",
    "\n",
    "> *Definición.* La probabilidad condicional de $\\beta$ dado $\\alpha$ se define como\n",
    "> $$P(\\beta| \\alpha) = \\frac{P(\\alpha \\cap \\beta)}{P(\\alpha)},$$\n",
    "> siempre que $P(\\alpha) \\neq 0$. En el caso en que $P(\\alpha) = 0$, la probabilidad condicional está indefinida.\n",
    "\n",
    "La interpretación (frecuentista) de esta definición es muy simple: La probabilidad condicional de $\\beta$ dado $\\alpha$ es la proporción relativa de los eventos que satisfacen $\\beta$ considerando únicamente los eventos que satisfacen $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Regla de la cadena y regla de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inmediatamente de la definición de probabilidad condicional, obtenemos que\n",
    "\n",
    "$$P(\\alpha \\cap \\beta) = P(\\alpha)P(\\beta| \\alpha).$$\n",
    "\n",
    "Esta igualdad se conoce como **regla de la cadena de proabilidades condicionales**.\n",
    "\n",
    "A partir de esto, es posible demostrar que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Proposición.* (**Regla de la cadena**) Sean $\\alpha_1,\\dots,\\alpha_k$ eventos, con $k\\in\\mathbb{N}$. Entonces,\n",
    ">\n",
    "> $$P(\\alpha_1\\cap\\dots\\cap\\alpha_k) = P(\\alpha_1)P(\\alpha_2|\\alpha_1)\\dots P(\\alpha_k|\\alpha_1, \\dots, \\alpha_k).$$\n",
    "\n",
    "> *Prueba.* Tarea ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, también partiendo de la definición de probabilidad condicional, se sigue la **regla de Bayes**:\n",
    "\n",
    "$$P(\\alpha | \\beta) = \\frac{P(\\beta | \\alpha) P(\\alpha)}{P(\\beta)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regla de Bayes es muy importante debido a quenos permite calcular la probabilidad condicional $P(\\alpha | \\beta)$  a partir de la probabilidad condicional \"inversa\" $P(\\beta | \\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Variables aleatorias (VA) y distribuciones conjuntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Variables aleatorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, nuestra discusión de distribuciones de probabilidad tenía que ver con eventos. Formalmente, podemos considerar cualquier evento del espacio de eventos.\n",
    "\n",
    "En este sentido, la descripción de los eventos la damos en términos de subconjuntos del espacio de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, resulta muchísimo más natural considerar *atributos* de los resultados. Por ejemplo, en el caso de los estudiantes, consideramos atributos como \"nota final\", \"edad\", \"género\", entre otros.\n",
    "\n",
    "De esta manera, nos interesa considerar eventos como \"nota final > 8\", o \"edad < 35\", entre otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La manera formal de razonar usando atributos de los diferentes resultados es usando el concepto de **variables aleatorias** (VA). Una VA es una manera de definir un evento de los resultados que satisfacen cierto atributo.\n",
    "\n",
    "Por ejemplo, la expresión $P(nota final > 8)$ representa la probabilidad de que un estudiante cualquiera obtenga una nota superior a 8.\n",
    "\n",
    "Formalmente,\n",
    "\n",
    "> *Definición.* Una **variable aleatoria** $X$ es una función que asocia a cada elemento en el espacio de resultados $\\Omega$ un valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera que si $X$ es por ejemplo la VA de nota final, usaremos de manera concisa la expresión $X>8$ para referirnos al evento ${\\omega\\in\\Omega: X(\\omega) > 8}$ de todos los estudiantes que obtuvieron una nota mayor a $8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usualmete, denotamos a las VA con letras mayúsculas, por ejemplo $X, Y, Z$; y usamos letras munúsculas para referirnos a valores arbitrarios de las VA. Por ejemplo, usamos expresiones como:\n",
    "\n",
    "$$P(X=x)\\geq 0, \\text{ para todo } x\\in\\mathrm{Val}(X),$$\n",
    "\n",
    "En la mayor parte del curso nos enfocaremos en VA discretas. En este caso diremos que $Val(X) = \\{x^1, \\dots, x^k\\}$ para referirnos que la VA $X$ puede tomar los valores $x^1, \\dots, x^k$, con $k=|Val(X)|\\in\\mathbb{N}$ (el número de elementos o cardinalidad), y tendremos que\n",
    "\n",
    "$$\\sum_{i=1}^{k}P(X=x^i)=???.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, usamos la notación \"barra\" para referirnos a **conjuntos de VA**, por ejemplo $\\bar{X}, \\bar{Y}, \\bar{Z}$ son conjuntos de VA. Así mismo, $\\bar{x}, \\bar{y}, \\bar{x}$ representan valores arbitrarios de dichos conjuntos de VA.\n",
    "\n",
    "De la misma manera extendemos la definición de $\\mathrm{Val}(\\bar{X})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Distribuciones marginales y conjuntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribución marginal**\n",
    "\n",
    "Una vez definimos la VA $X$, podemos considerar la distribución de probabilidad sobre eventos que pueden ser descritos usando $X$. Esta distribución la conocemos como **distribución marginal** sobre la VA $X$, y la denotamos como $P(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo del estudiante podemos considerar las VA, $I$(nteligencia) y $N$(ota). \n",
    "\n",
    "Consideramos lo siguiente:\n",
    " - $\\mathrm{Val}(I) = \\{i^0, i^1\\}$, donde $i^1$: inteligente e $i^0$: no tanto.\n",
    " - $\\mathrm{Val}(N) = \\{n^0, n^1, n^2\\}$, donde $n^2$: nota mayor o igual 8; $n^1$: nota mayor o igual a 6 y menor que 8; y $n^0$: nota menor que 6.\n",
    " \n",
    "De manera que para especificar completamente la distribución marginal sobre $I$, necesitamos poder especificar las probabilidades para cada valor de $I$. Concretamente $P(I=i^0) = 0.7$ y $P(I=i^0) = 0.3$.\n",
    "\n",
    "Similarmente, para $N$, $P(N=n^0) = 0.38$, $P(N=n^1) = 0.37$, y $P(N=n^2) = 0.25$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribución conjunta**\n",
    "\n",
    "Por otra parte, es muy común que estemos interesados en razonar acerca de varios atributos a la vez. Por ejemplo, nos interesaría el evento $(I=i^1, N=n^2)$.\n",
    "\n",
    "Para poder razonar de esta manera, debemos considerar la **distribución conjunta** sobre estas dos VA.\n",
    "\n",
    "En general, la distribución conjunta sobre un conjunto de VA $\\bar{X}=\\{X_1,\\dots,X_n\\}$ la denotamos por\n",
    "\n",
    "$$P(X_1,\\dots,X_n)$$\n",
    "\n",
    "y es una distribución que asigna probabilidades a eventos que se especifican en términos de dichas VA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, la distribución conjunta debe ser coherente con la distribución marginal en el sentido que:\n",
    "\n",
    "$$P(X=x) = \\sum_{y} P(X=x, Y=y).$$\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='joint.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, cabe mencionar que las nociones de probabilidad condicional, regla de la cadena y regla de Bayes se extienden naturalmente a VA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Independencia e independencia condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Independencia\n",
    "\n",
    "Al definir el concepto de probabilidad condicional lo motivamos porque es el mecanismo básico para incluir evidencia en nuestro razonamiento. De esta manera esperamos, en general que $P(\\alpha | \\beta) \\neq P(\\alpha)$.\n",
    "\n",
    "Sin embargo, lo anterior puede no ocurrir en ciertas ocasiones, de manera que $P(\\alpha | \\beta) = P(\\alpha)$. Es decir, el conocer $\\beta$ no cambia en absoluto la probabilidad del evento $\\alpha$. Este concepto lo conocemos como **independencia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Definición.* Decimos que un evento $\\alpha$ es independiente de un evento $\\beta$ en $P$, o que $P$ satisface $\\alpha \\perp \\beta$, si $P(\\alpha|\\beta) = P(\\alpha)$, o si $P(\\beta)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalentemente,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Proposición.* $P$ satisface $\\alpha \\perp \\beta$ si y solo si $P(\\alpha \\cap \\beta) = P(\\alpha) P(\\beta).$\n",
    "\n",
    "> *Prueba.* En clase ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consecuencia inmediata de la anterior proposición, se sigue que la noción de independencia es simétrica. Esto es, si $\\alpha \\perp \\beta$ entonces $\\beta \\perp \\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, podemos tomar la situación de tirar una moneda al aire.\n",
    "\n",
    "1. Sean:\n",
    "   - $\\alpha$: en la primera tirada cae cara;\n",
    "   - $\\beta$: en la segunda tirada cae cara.\n",
    "   \n",
    "   Analizar la independencia.\n",
    "   \n",
    "2. Sean:\n",
    "   - $\\alpha$: en las dos primeras tiradas cae cara;\n",
    "   - $\\beta$: en las tres primeras tiradas cae cara.\n",
    "   \n",
    "   Analizar la independencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Independencia condicional.\n",
    "\n",
    "La independencia es una propiedad muy útil. Sin embargo, no es muy común encontrar eventos independientes cuando se analizan situaciones.\n",
    "\n",
    "Por otra parte, una situación más común es encontrar eventos independientes dado un evento adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, supongamos que un estudiante aplica a dos prácticas profesionales en las empresas A y B al mismo tiempo. Sean\n",
    "\n",
    "- $\\alpha$: aceptado en empresa A;\n",
    "- $\\beta$: aceptado en empresa B.\n",
    "\n",
    "Estos dos eventos, no son independientes en principio, pues saber que $\\alpha$ es cierto, aumenta la probabilidad de $\\beta$ y vice versa. Por otra parte, supongamos que las empresas toman la decisión de a quién aceptar con base en el promedio en la carrera, únicamente. Sea\n",
    "\n",
    "- $\\gamma$: promedio de 9.5.\n",
    "\n",
    "En este caso, si sabemos que $\\gamma$ es cierto, podemos pensar entonces que estos eventos se vuelven independientes, pues saber ahora que $\\alpha$ es cierto, no influye la probabilidad de $\\beta$.\n",
    "\n",
    "De manera que escribiríamos: $P(\\beta | \\alpha \\cap \\gamma) = P(\\beta | \\gamma)$, y diríamos que $\\beta$ es condicionalmente independiente de $\\alpha$ dado $\\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Definición.* Decimos que un evento $\\alpha$ es condicionalmente independiente de $\\beta$ dado $\\gamma$ en $P$, o que $P$ satisface $(\\alpha \\perp \\beta | \\gamma)$, si $P(\\alpha|\\beta \\cap \\gamma) = P(\\alpha | \\gamma)$, o si $P(\\beta \\cap \\gamma)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalentemente,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Proposición.* $P$ satisface $(\\alpha \\perp \\beta | \\gamma)$ si y solo si $P(\\alpha \\cap \\beta | \\gamma) = P(\\alpha | \\gamma) P(\\beta | \\gamma).$\n",
    "\n",
    "> *Prueba.* Tarea ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Independencia en VA\n",
    "\n",
    "Las nociones de independencia se extienden naturalmente a VA:\n",
    "\n",
    "> *Definición.* Sean $\\bar{X}$, $\\bar{Y}$ y $\\bar{Z}$ conjuntos de VA. Decimos que $\\bar{X}$ es condicionalmente independiente de $\\bar{Y}$ dado $\\bar{Z}$ en un distribución $P$, si $P$ satisface $(\\bar{X} = \\bar{x} \\perp \\bar{Y} = \\bar{y} | \\bar{Z} = \\bar{z})$ para todo $\\bar{x}\\in\\mathrm{Val}(\\bar{X})$, $\\bar{y}\\in\\mathrm{Val}(\\bar{Y})$ y $\\bar{z}\\in\\mathrm{Val}(\\bar{Z})$.\n",
    ">\n",
    "> Las variables en el conjunto $\\bar{Z}$ se dice que son observadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Proposición.* $P$ satisface $(\\bar{X} \\perp \\bar{Y} | \\bar{Z})$ si y solo si $P(\\bar{X}, \\bar{Y} | \\bar{Z}) = P(\\bar{X} | \\bar{Z}) P(\\bar{Y} | \\bar{Z}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, supongamos que conocemos ciertas independencias condicionales en una distribución. Podemos obtener otras independencias a partir de las que ya conocemos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Simetría**\n",
    "   $$(\\bar{X} \\perp \\bar{Y} | \\bar{Z}) \\Rightarrow (\\bar{Y} \\perp \\bar{X} | \\bar{Z}).$$\n",
    "   \n",
    "2. **Descomposición**\n",
    "   $$(\\bar{X} \\perp \\bar{Y}, \\bar{W} | \\bar{Z}) \\Rightarrow (\\bar{X} \\perp \\bar{Y} | \\bar{Z}).$$\n",
    "   \n",
    "3. **Unión débil**\n",
    "   $$(\\bar{X} \\perp \\bar{Y}, \\bar{W} | \\bar{Z}) \\Rightarrow (\\bar{X} \\perp \\bar{Y} | \\bar{Z}, \\bar{W}).$$\n",
    "   \n",
    "4. **Contracción**\n",
    "   $$(\\bar{X} \\perp \\bar{W} | \\bar{Z}, \\bar{Y}) \\& (\\bar{X} \\perp \\bar{Y} | \\bar{Z}) \\Rightarrow (\\bar{X} \\perp \\bar{Y}, \\bar{W} | \\bar{Z}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Prueba.* Tarea ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anuncios parroquiales\n",
    "\n",
    "### 1. Quiz la siguiente clase.\n",
    "### 2. Tarea 1 para el viernes.\n",
    "### 3. [Lectura recomendada](https://medium.com/causal-data-science/if-correlation-doesnt-imply-causation-then-what-does-c74f20d26438).\n",
    "### 4. Para los más visuales, les recomiendo este [material](https://seeing-theory.brown.edu/basic-probability/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
